package messaging

import (
	"context"
	"fmt"
	"sync"
	"time"

	"greatestworks/internal/events"
	"greatestworks/internal/infrastructure/logging"
)

// EventDispatcher äº‹ä»¶åˆ†å‘å™?
type EventDispatcher struct {
	publisher  Publisher
	subscriber Subscriber
	logger     logger.Logger
	config     *DispatcherConfig
	handlers   map[string][]events.EventHandler
	mu         sync.RWMutex
	stats      *DispatcherStats
	ctx        context.Context
	cancel     context.CancelFunc
	eventQueue chan *EventMessage
	workerPool *WorkerPool
}

// DispatcherConfig åˆ†å‘å™¨é…ç½?
type DispatcherConfig struct {
	WorkerCount       int           `json:"worker_count" yaml:"worker_count"`
	QueueSize         int           `json:"queue_size" yaml:"queue_size"`
	BatchSize         int           `json:"batch_size" yaml:"batch_size"`
	BatchTimeout      time.Duration `json:"batch_timeout" yaml:"batch_timeout"`
	RetryAttempts     int           `json:"retry_attempts" yaml:"retry_attempts"`
	RetryDelay        time.Duration `json:"retry_delay" yaml:"retry_delay"`
	EnableMetrics     bool          `json:"enable_metrics" yaml:"enable_metrics"`
	EnableDeadLetter  bool          `json:"enable_dead_letter" yaml:"enable_dead_letter"`
	MaxProcessingTime time.Duration `json:"max_processing_time" yaml:"max_processing_time"`
}

// EventMessage äº‹ä»¶æ¶ˆæ¯
type EventMessage struct {
	Event      DomainEvent       `json:"event"`
	Timestamp  time.Time         `json:"timestamp"`
	RetryCount int               `json:"retry_count"`
	Metadata   map[string]string `json:"metadata"`
}

// Dispatcher äº‹ä»¶åˆ†å‘å™¨æ¥å?
type Dispatcher interface {
	// RegisterHandler æ³¨å†Œäº‹ä»¶å¤„ç†å™?
	RegisterHandler(eventType string, handler events.EventHandler) error

	// UnregisterHandler å–æ¶ˆæ³¨å†Œäº‹ä»¶å¤„ç†å™?
	UnregisterHandler(eventType string, handlerName string) error

	// Dispatch åˆ†å‘äº‹ä»¶
	Dispatch(ctx context.Context, event DomainEvent) error

	// DispatchAsync å¼‚æ­¥åˆ†å‘äº‹ä»¶
	DispatchAsync(ctx context.Context, event DomainEvent) error

	// DispatchBatch æ‰¹é‡åˆ†å‘äº‹ä»¶
	DispatchBatch(ctx context.Context, events []DomainEvent) error

	// Start å¯åŠ¨åˆ†å‘å™?
	Start(ctx context.Context) error

	// Stop åœæ­¢åˆ†å‘å™?
	Stop() error

	// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
	GetStats() *DispatcherStats
}

// NewEventDispatcher åˆ›å»ºäº‹ä»¶åˆ†å‘å™?
func NewEventDispatcher(publisher Publisher, subscriber Subscriber, config *DispatcherConfig, logger logger.Logger) Dispatcher {
	if config == nil {
		config = &DispatcherConfig{
			WorkerCount:       10,
			QueueSize:         1000,
			BatchSize:         100,
			BatchTimeout:      5 * time.Second,
			RetryAttempts:     3,
			RetryDelay:        1 * time.Second,
			EnableMetrics:     true,
			EnableDeadLetter:  true,
			MaxProcessingTime: 30 * time.Second,
		}
	}

	ctx, cancel := context.WithCancel(context.Background())

	d := &EventDispatcher{
		publisher:  publisher,
		subscriber: subscriber,
		logger:     logger,
		config:     config,
		handlers:   make(map[string][]events.EventHandler),
		ctx:        ctx,
		cancel:     cancel,
		eventQueue: make(chan *EventMessage, config.QueueSize),
		stats: &DispatcherStats{
			StartTime:   time.Now(),
			ByEventType: make(map[string]*EventTypeStats),
			ByHandler:   make(map[string]*HandlerStats),
		},
	}

	// åˆ›å»ºå·¥ä½œæ±?
	d.workerPool = NewWorkerPool(config.WorkerCount, d.processEvent, logger)

	logger.Info("Event dispatcher initialized successfully", "worker_count", config.WorkerCount, "queue_size", config.QueueSize)
	return d
}

// RegisterHandler æ³¨å†Œäº‹ä»¶å¤„ç†å™?
func (d *EventDispatcher) RegisterHandler(eventType string, handler events.EventHandler) error {
	d.mu.Lock()
	defer d.mu.Unlock()

	// æ£€æŸ¥å¤„ç†å™¨æ˜¯å¦å·²å­˜åœ?
	for _, existingHandler := range d.handlers[eventType] {
		if existingHandler.GetHandlerName() == handler.GetHandlerName() {
			return fmt.Errorf("handler %s already registered for event type %s", handler.GetHandlerName(), eventType)
		}
	}

	// æ·»åŠ å¤„ç†å™?
	d.handlers[eventType] = append(d.handlers[eventType], handler)

	// è®¢é˜…äº‹ä»¶
	if err := d.subscriber.SubscribeEvent(eventType, handler); err != nil {
		d.logger.Error("Failed to subscribe to event", "error", err, "event_type", eventType, "handler", handler.GetHandlerName())
		return fmt.Errorf("failed to subscribe to event %s: %w", eventType, err)
	}

	d.logger.Info("Event handler registered successfully", "event_type", eventType, "handler", handler.GetHandlerName())
	return nil
}

// UnregisterHandler å–æ¶ˆæ³¨å†Œäº‹ä»¶å¤„ç†å™?
func (d *EventDispatcher) UnregisterHandler(eventType string, handlerName string) error {
	d.mu.Lock()
	defer d.mu.Unlock()

	handlers := d.handlers[eventType]
	for i, handler := range handlers {
		if handler.GetHandlerName() == handlerName {
			// ç§»é™¤å¤„ç†å™?
			d.handlers[eventType] = append(handlers[:i], handlers[i+1:]...)

			// å¦‚æœæ²¡æœ‰æ›´å¤šå¤„ç†å™¨ï¼Œå–æ¶ˆè®¢é˜…
			if len(d.handlers[eventType]) == 0 {
				delete(d.handlers, eventType)
				// è¿™é‡Œåº”è¯¥å–æ¶ˆè®¢é˜…ï¼Œä½†NATSè®¢é˜…æ˜¯æŒ‰ä¸»é¢˜çš„ï¼Œå¯èƒ½æœ‰å…¶ä»–å¤„ç†å™¨
			}

			d.logger.Info("Event handler unregistered successfully", "event_type", eventType, "handler", handlerName)
			return nil
		}
	}

	return fmt.Errorf("handler %s not found for event type %s", handlerName, eventType)
}

// Dispatch åˆ†å‘äº‹ä»¶
func (d *EventDispatcher) Dispatch(ctx context.Context, event DomainEvent) error {
	// ç›´æ¥å‘å¸ƒäº‹ä»¶
	err := d.publisher.PublishEvent(ctx, event)
	if err != nil {
		d.updateStats(event.GetEventType(), false, 0, "publish_error")
		d.logger.Error("Failed to dispatch event", "error", err, "event_type", event.GetEventType(), "event_id", event.GetEventID())
		return fmt.Errorf("failed to dispatch event: %w", err)
	}

	d.updateStats(event.GetEventType(), true, 0, "dispatched")
	d.logger.Debug("Event dispatched successfully", "event_type", event.GetEventType(), "event_id", event.GetEventID())
	return nil
}

// DispatchAsync å¼‚æ­¥åˆ†å‘äº‹ä»¶
func (d *EventDispatcher) DispatchAsync(ctx context.Context, event DomainEvent) error {
	eventMsg := &EventMessage{
		Event:      event,
		Timestamp:  time.Now(),
		RetryCount: 0,
		Metadata:   make(map[string]string),
	}

	// æ·»åŠ åˆ°é˜Ÿåˆ?
	select {
	case d.eventQueue <- eventMsg:
		d.updateStats(event.GetEventType(), true, 0, "queued")
		d.logger.Debug("Event queued for async dispatch", "event_type", event.GetEventType(), "event_id", event.GetEventID())
		return nil
	case <-ctx.Done():
		return ctx.Err()
	default:
		d.updateStats(event.GetEventType(), false, 0, "queue_full")
		return fmt.Errorf("event queue is full")
	}
}

// DispatchBatch æ‰¹é‡åˆ†å‘äº‹ä»¶
func (d *EventDispatcher) DispatchBatch(ctx context.Context, events []DomainEvent) error {
	if len(events) == 0 {
		return nil
	}

	// æ„å»ºæ‰¹é‡æ¶ˆæ¯
	batchMessages := make([]BatchMessage, len(events))
	for i, event := range events {
		batchMessages[i] = BatchMessage{
			Subject: fmt.Sprintf("events.%s.%s", event.GetAggregateType(), event.GetEventType()),
			Data:    event,
		}
	}

	// æ‰¹é‡å‘å¸ƒ
	err := d.publisher.PublishBatch(ctx, batchMessages)
	if err != nil {
		for _, event := range events {
			d.updateStats(event.GetEventType(), false, 0, "batch_error")
		}
		d.logger.Error("Failed to dispatch batch events", "error", err, "count", len(events))
		return fmt.Errorf("failed to dispatch batch events: %w", err)
	}

	// æ›´æ–°ç»Ÿè®¡
	for _, event := range events {
		d.updateStats(event.GetEventType(), true, 0, "batch_dispatched")
	}

	d.logger.Debug("Batch events dispatched successfully", "count", len(events))
	return nil
}

// Start å¯åŠ¨åˆ†å‘å™?
func (d *EventDispatcher) Start(ctx context.Context) error {
	d.logger.Info("Starting event dispatcher")

	// å¯åŠ¨å·¥ä½œæ±?
	if err := d.workerPool.Start(d.ctx); err != nil {
		return fmt.Errorf("failed to start worker pool: %w", err)
	}

	// å¯åŠ¨é˜Ÿåˆ—å¤„ç†å™?
	go d.processQueue()

	// å¯åŠ¨æ‰¹å¤„ç†å™¨
	go d.processBatch()

	// å¯åŠ¨æŒ‡æ ‡æ”¶é›†
	if d.config.EnableMetrics {
		go d.collectMetrics()
	}

	// å¯åŠ¨è®¢é˜…è€?
	go func() {
		if err := d.subscriber.Start(d.ctx); err != nil {
			d.logger.Error("Subscriber stopped with error", "error", err)
		}
	}()

	// ç­‰å¾…ä¸Šä¸‹æ–‡å–æ¶?
	select {
	case <-ctx.Done():
		d.logger.Info("Event dispatcher context cancelled")
		return ctx.Err()
	case <-d.ctx.Done():
		d.logger.Info("Event dispatcher stopped")
		return nil
	}
}

// Stop åœæ­¢åˆ†å‘å™?
func (d *EventDispatcher) Stop() error {
	d.logger.Info("Stopping event dispatcher")

	// å–æ¶ˆä¸Šä¸‹æ–?
	d.cancel()

	// åœæ­¢å·¥ä½œæ±?
	if err := d.workerPool.Stop(); err != nil {
		d.logger.Error("Failed to stop worker pool", "error", err)
	}

	// åœæ­¢è®¢é˜…è€?
	if err := d.subscriber.Stop(); err != nil {
		d.logger.Error("Failed to stop subscriber", "error", err)
	}

	// å…³é—­å‘å¸ƒè€?
	if err := d.publisher.Close(); err != nil {
		d.logger.Error("Failed to close publisher", "error", err)
	}

	// å…³é—­äº‹ä»¶é˜Ÿåˆ—
	close(d.eventQueue)

	d.logger.Info("Event dispatcher stopped successfully")
	return nil
}

// GetStats è·å–ç»Ÿè®¡ä¿¡æ¯
func (d *EventDispatcher) GetStats() *DispatcherStats {
	d.mu.RLock()
	defer d.mu.RUnlock()

	// åˆ›å»ºç»Ÿè®¡ä¿¡æ¯å‰¯æœ¬
	stats := &DispatcherStats{
		TotalDispatched: d.stats.TotalDispatched,
		TotalFailed:     d.stats.TotalFailed,
		QueueSize:       int64(len(d.eventQueue)),
		WorkerCount:     int64(d.config.WorkerCount),
		StartTime:       d.stats.StartTime,
		Uptime:          time.Since(d.stats.StartTime),
		ByEventType:     make(map[string]*EventTypeStats),
		ByHandler:       make(map[string]*HandlerStats),
	}

	// å¤åˆ¶äº‹ä»¶ç±»å‹ç»Ÿè®¡
	for eventType, eventStats := range d.stats.ByEventType {
		stats.ByEventType[eventType] = &EventTypeStats{
			DispatchedCount: eventStats.DispatchedCount,
			FailedCount:     eventStats.FailedCount,
			LastDispatched:  eventStats.LastDispatched,
			AvgProcessTime:  eventStats.AvgProcessTime,
		}
	}

	// å¤åˆ¶å¤„ç†å™¨ç»Ÿè®?
	for handlerName, handlerStats := range d.stats.ByHandler {
		stats.ByHandler[handlerName] = &HandlerStats{
			ProcessedCount: handlerStats.ProcessedCount,
			FailedCount:    handlerStats.FailedCount,
			LastProcessed:  handlerStats.LastProcessed,
			AvgProcessTime: handlerStats.AvgProcessTime,
		}
	}

	return stats
}

// ç§æœ‰æ–¹æ³•

// processQueue å¤„ç†äº‹ä»¶é˜Ÿåˆ—
func (d *EventDispatcher) processQueue() {
	for {
		select {
		case eventMsg := <-d.eventQueue:
			if eventMsg != nil {
				// æäº¤åˆ°å·¥ä½œæ± 
				d.workerPool.Submit(eventMsg)
			}
		case <-d.ctx.Done():
			return
		}
	}
}

// processBatch å¤„ç†æ‰¹é‡äº‹ä»¶
func (d *EventDispatcher) processBatch() {
	ticker := time.NewTicker(d.config.BatchTimeout)
	defer ticker.Stop()

	batch := make([]*EventMessage, 0, d.config.BatchSize)

	for {
		select {
		case eventMsg := <-d.eventQueue:
			if eventMsg != nil {
				batch = append(batch, eventMsg)

				// å¦‚æœæ‰¹æ¬¡æ»¡äº†ï¼Œç«‹å³å¤„ç?
				if len(batch) >= d.config.BatchSize {
					d.processBatchEvents(batch)
					batch = batch[:0] // é‡ç½®æ‰¹æ¬¡
				}
			}
		case <-ticker.C:
			// å®šæ—¶å¤„ç†æ‰¹æ¬¡
			if len(batch) > 0 {
				d.processBatchEvents(batch)
				batch = batch[:0] // é‡ç½®æ‰¹æ¬¡
			}
		case <-d.ctx.Done():
			// å¤„ç†å‰©ä½™æ‰¹æ¬¡
			if len(batch) > 0 {
				d.processBatchEvents(batch)
			}
			return
		}
	}
}

// processBatchEvents å¤„ç†æ‰¹é‡äº‹ä»¶
func (d *EventDispatcher) processBatchEvents(batch []*EventMessage) {
	events := make([]DomainEvent, len(batch))
	for i, eventMsg := range batch {
		events[i] = eventMsg.Event
	}

	ctx, cancel := context.WithTimeout(d.ctx, d.config.MaxProcessingTime)
	defer cancel()

	if err := d.DispatchBatch(ctx, events); err != nil {
		d.logger.Error("Failed to process batch events", "error", err, "count", len(batch))

		// é‡è¯•å•ä¸ªäº‹ä»¶
		for _, eventMsg := range batch {
			d.retryEvent(eventMsg)
		}
	}
}

// processEvent å¤„ç†å•ä¸ªäº‹ä»¶
func (d *EventDispatcher) processEvent(data interface{}) error {
	eventMsg, ok := data.(*EventMessage)
	if !ok {
		return fmt.Errorf("invalid event message type")
	}

	start := time.Now()

	ctx, cancel := context.WithTimeout(d.ctx, d.config.MaxProcessingTime)
	defer cancel()

	err := d.Dispatch(ctx, eventMsg.Event)
	processTime := time.Since(start)

	if err != nil {
		d.updateStats(eventMsg.Event.GetEventType(), false, processTime, "process_error")

		// é‡è¯•é€»è¾‘
		if eventMsg.RetryCount < d.config.RetryAttempts {
			d.retryEvent(eventMsg)
		} else {
			d.logger.Error("Event processing failed after max retries", "error", err, "event_type", eventMsg.Event.GetEventType(), "retry_count", eventMsg.RetryCount)
		}
		return err
	}

	d.updateStats(eventMsg.Event.GetEventType(), true, processTime, "processed")
	return nil
}

// retryEvent é‡è¯•äº‹ä»¶
func (d *EventDispatcher) retryEvent(eventMsg *EventMessage) {
	eventMsg.RetryCount++

	// å»¶è¿Ÿé‡è¯•
	go func() {
		time.Sleep(d.config.RetryDelay * time.Duration(eventMsg.RetryCount))

		select {
		case d.eventQueue <- eventMsg:
			d.logger.Debug("Event queued for retry", "event_type", eventMsg.Event.GetEventType(), "retry_count", eventMsg.RetryCount)
		case <-d.ctx.Done():
			return
		default:
			d.logger.Error("Failed to queue event for retry - queue full", "event_type", eventMsg.Event.GetEventType())
		}
	}()
}

// updateStats æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
func (d *EventDispatcher) updateStats(eventType string, success bool, processTime time.Duration, operation string) {
	d.mu.Lock()
	defer d.mu.Unlock()

	if success {
		d.stats.TotalDispatched++
	} else {
		d.stats.TotalFailed++
	}

	// æ›´æ–°äº‹ä»¶ç±»å‹ç»Ÿè®¡
	eventStats, exists := d.stats.ByEventType[eventType]
	if !exists {
		eventStats = &EventTypeStats{}
		d.stats.ByEventType[eventType] = eventStats
	}

	if success {
		eventStats.DispatchedCount++
		eventStats.LastDispatched = time.Now()

		// æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
		if eventStats.AvgProcessTime == 0 {
			eventStats.AvgProcessTime = processTime
		} else {
			eventStats.AvgProcessTime = (eventStats.AvgProcessTime + processTime) / 2
		}
	} else {
		eventStats.FailedCount++
	}
}

// collectMetrics æ”¶é›†æŒ‡æ ‡
func (d *EventDispatcher) collectMetrics() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			stats := d.GetStats()
			d.logger.Debug("Dispatcher metrics",
				"total_dispatched", stats.TotalDispatched,
				"total_failed", stats.TotalFailed,
				"queue_size", stats.QueueSize,
				"worker_count", stats.WorkerCount,
				"uptime", stats.Uptime)
		case <-d.ctx.Done():
			return
		}
	}
}

// ç»Ÿè®¡ä¿¡æ¯ç»“æ„
type DispatcherStats struct {
	TotalDispatched int64                      `json:"total_dispatched"`
	TotalFailed     int64                      `json:"total_failed"`
	QueueSize       int64                      `json:"queue_size"`
	WorkerCount     int64                      `json:"worker_count"`
	StartTime       time.Time                  `json:"start_time"`
	Uptime          time.Duration              `json:"uptime"`
	ByEventType     map[string]*EventTypeStats `json:"by_event_type"`
	ByHandler       map[string]*HandlerStats   `json:"by_handler"`
}

type EventTypeStats struct {
	DispatchedCount int64         `json:"dispatched_count"`
	FailedCount     int64         `json:"failed_count"`
	LastDispatched  time.Time     `json:"last_dispatched"`
	AvgProcessTime  time.Duration `json:"avg_process_time"`
}

type HandlerStats struct {
	ProcessedCount int64         `json:"processed_count"`
	FailedCount    int64         `json:"failed_count"`
	LastProcessed  time.Time     `json:"last_processed"`
	AvgProcessTime time.Duration `json:"avg_process_time"`
}
